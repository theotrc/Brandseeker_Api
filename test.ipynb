{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theo/anaconda3/envs/flaskenv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pytube import YouTube\n",
    "import torch\n",
    "from utils.general import (check_file, check_img_size, cv2, non_max_suppression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = YouTube('https://www.youtube.com/watch?v=WfuE61ZkuRo')\n",
    "video = yt.streams.filter(file_extension='mp4').first()\n",
    "video.download('video/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "def pytube_dl(url):\n",
    "    yt = YouTube(str(url))\n",
    "    video = yt.streams.filter(file_extension='mp4').first()\n",
    "    video.download('video/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/theo/.var/app/com.visualstudio.code/cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-7-5 Python-3.10.4 torch-1.12.0+cu102 CPU\n",
      "\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /home/theo/Desktop/apiBrandseeker/requirements.txt not found, check failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model summary: 213 layers, 7112611 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for path, im, im0s, vid_cap, s, frame in tqdm(dataset, total=total_frames):\n",
    "    i+=1\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.torch_utils import select_device, time_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-7-5 Python-3.10.4 torch-1.12.0+cu102 CPU\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.filtering import filter_output\n",
    "from utils.pdf_generator import pdf_generator, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-7-5 Python-3.10.4 torch-1.12.0+cu102 CPU\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 33687/35128 [03:30<00:08, 160.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Winamax': [1.6746974454223433, 0.7869841456413269, 14730, [279.46917724609375, 143.6875457763672, 421.904052734375, 275.8118896484375]], 'Lootcrate': [0.09001361782811455, 0.7459093630313873, 675, [12.015167236328125, 12.05072021484375, 619.912109375, 345.76708984375]], 'Manscaped': [0.10441062780983588, 0.6591405272483826, 3090, [22.774757385253906, 259.8238525390625, 219.39822387695312, 315.1514892578125]], 'Uber Eats': [0.15801738860836173, 0.39638763666152954, 18570, [578.1520385742188, 57.36253356933594, 608.5293579101562, 72.75448608398438]]}\n",
      "Pred took 251.39s (69.87fps)\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='weights/best.pt')\n",
    "\n",
    "stride, names, pt = model.stride, model.names, model.pt\n",
    "imgsz = check_img_size((640, 640), s=stride)  \n",
    "\n",
    "dataset = LoadImages(\"video/\", img_size=imgsz, stride=stride, auto=pt, only_vids=True)\n",
    "bs = 1\n",
    "brand_count = {}\n",
    "path, im, im0s, vid_cap, s, frame = dataset.__iter__().__next__()\n",
    "\n",
    "framerate = 1\n",
    "initial_framerate = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "real_framerate = initial_framerate / round(initial_framerate / framerate)\n",
    "total_frames = dataset.frames\n",
    "dataset.frame = 0\n",
    "\n",
    "total_frames = dataset.frames\n",
    "device = select_device('')\n",
    "dt, seen = [0.0, 0.0, 0.0], 0\n",
    "\n",
    "save_dir = \"saving_predict\"\n",
    "save_unprocessed_output = False\n",
    "pred_timing_start = time_sync()\n",
    "\n",
    "for path, im, im0s, vid_cap, s, frame in tqdm(dataset, total=total_frames):\n",
    "\n",
    "        # skip the frame if it isn't in the specified framerate\n",
    "        if frame % round(initial_framerate / framerate) != 0:\n",
    "            continue\n",
    "\n",
    "        t1 = time_sync()\n",
    "        im = torch.from_numpy(im).to(device)\n",
    "        im = im.float()\n",
    "        im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "\n",
    "        if len(im.shape) == 3:\n",
    "            im = im[None]  # expand for batch dim\n",
    "        t2 = time_sync()\n",
    "        dt[0] += t2 - t1\n",
    "\n",
    "        # Inference\n",
    "        pred = model(im)\n",
    "        t3 = time_sync()\n",
    "        dt[1] += t3 - t2\n",
    "\n",
    "        # NMS\n",
    "        pred = non_max_suppression(pred, conf_thres=0.35, max_det=5)\n",
    "        pred = pred[0].tolist()\n",
    "        dt[2] += time_sync() - t3\n",
    "\n",
    "        has_prediction = len(pred)\n",
    "        if has_prediction:\n",
    "            for brand in pred:\n",
    "                label = names[int(brand[5])]\n",
    "\n",
    "                # Retrieve or create a dictionnary key for the label and add the bbox, confidence and frame of the prediction\n",
    "                brand_count[label] = brand_count.get(label, {\"bbox\": [], \"confidence\": [], \"frame\": []})\n",
    "                brand_count[label][\"bbox\"].append(brand[0:4])\n",
    "                brand_count[label][\"confidence\"].append(brand[4])\n",
    "                brand_count[label][\"frame\"].append(frame)\n",
    "    \n",
    "    # Generate an output if a prediction has been made\n",
    "if brand_count:\n",
    "    filtered_output = filter_output(brand_count, framerate)\n",
    "    pdf_generator(path, filtered_output, save_dir)\n",
    "    # cv2.imshow(im, framerate)\n",
    "\n",
    "    if save_unprocessed_output:\n",
    "        with open(f\"{save_dir}/{normalize(path)}.txt\", \"w\") as f:\n",
    "            f.write(str(brand_count))\n",
    "else:\n",
    "    print(\"No prediction has been made\")\n",
    "\n",
    "\n",
    "pred_timing_stop = time_sync()\n",
    "pred_timing = pred_timing_stop - pred_timing_start\n",
    "print(\"Pred took %.2fs (%.2ffps)\" % (pred_timing, ((total_frames / initial_framerate) * real_framerate) / pred_timing))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67aaf1d5ed21201ba7a8b0f60d8490dc144250f7c4f404e185860014192452eb"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('flaskenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
